---
title: "诊断延迟问题"
linkTitle: "延迟诊断"
weight: 1
description: 寻找慢响应的原因
aliases: [
    /topics/latency,
    /docs/reference/optimization/latency
]
---

以下文档将帮助您了解如果您在使用Redis时遇到延迟问题可能出现的问题。

在这种情况下，*延迟*是指客户端发出命令和客户端接收到命令回复之间的最大延迟时间。通常情况下，Redis的处理时间非常低，处于亚微秒的范围内，但在某些情况下可能会出现较高的延迟。

我时间有限，给我清单。
---

以下文档对于以低延迟方式运行Redis非常重要。但是我知道我们都很忙，所以我们先来看一个快速的检查列表。如果您在遵循这些步骤时失败，请返回此处阅读完整的文档。

1. 确保您没有运行阻塞服务器的慢命令。使用Redis [Slow Log功能](/commands/slowlog)来检查。
2. 对于使用EC2的用户，请确保使用基于HVM的现代EC2实例，如m3.medium。否则fork()太慢。
3. 必须禁用内核中的透明大页面。使用`echo never > /sys/kernel/mm/transparent_hugepage/enabled`来禁用它们，并重新启动Redis进程。
4. 如果您使用的是虚拟机，那么您可能会有与Redis无关的固有延迟。使用`./redis-cli --intrinsic-latency 100`检查您运行时环境的最小延迟。注意：您需要在*服务器端*而不是在客户端运行此命令。
5. 启用并使用Redis的[延迟监视器](/topics/latency-monitor)功能，以获取Redis实例中延迟事件和原因的人类可读描述。

一般情况下，根据耐久性与延迟/性能折衷的情况，使用以下表格，按安全性强到延迟更好的顺序排列。

1. AOF + fsync始终：这样做非常慢，只有在知道自己在做什么时才应该使用它。
2. AOF + 每秒fsync：这是一个很好的折中方案。
3. AOF + 每秒fsync + yes设置为no-appendfsync-on-rewrite选项：与上述相同，但在重写期间避免了fsync，以降低磁盘压力。
4. AOF + 从不fsync。在这种设置中，fsync由内核负责，磁盘压力更小，延迟峰值风险更低。
5. RDB。在这里，您可以根据配置的保存触发器进行大范围的权衡。

现在让我们为那些有15分钟时间的人提供详细信息...

测量延迟
-----------------

如果您遇到延迟问题，您可能已经知道如何在应用程序环境中进行测量，或者您的延迟问题在宏观上非常明显。但是，redis-cli可以用来以毫秒为单位测量Redis服务器的延迟，请尝试：

    redis-cli --latency -h `host` -p `port`

使用内部的Redis延迟监控子系统

自从 Redis 2.8.13 版本以来，Redis 提供了延迟监控能力，能够采样不同的执行路径以了解服务器的阻塞情况。这使得在这份文档中所阐述的问题的调试变得更加简单，因此我们建议尽快启用延迟监控。请参考 [延迟监控文档](/topics/latency-monitor)。

虽然延迟监控采样和报告功能可以更容易地理解Redis系统中延迟的来源，但建议您仔细阅读本文档以更好地理解Redis和延迟峰值的主题。

延迟基准线
----------------

有一种延迟是环境中固有的，无论您在哪里运行Redis，都会有这种延迟，这就是由操作系统内核和（如果您使用虚拟化）您使用的虚拟化管理程序提供的延迟。

这种延迟无法消除，但研究它很重要，因为它是基准，换句话说，由于内核或虚拟机监控程序的实现或配置，您无法实现比运行环境中的每个进程都会遇到的 Redis 延迟更好的延迟。

我们将这种延迟称为“内在延迟”，从Redis版本2.8.7开始，`redis-cli`可以测量它。这是在Linux 3.11.0上运行在入门级服务器上的示例运行。

注意：参数`100`是测试执行的秒数。运行测试的时间越长，我们就越有可能发现延迟峰值。通常情况下，100秒是适当的，但您可能希望在不同时间进行几次运行。请注意，该测试对CPU要求较高，可能会使您系统中的一个核心饱和。

    $ ./redis-cli --intrinsic-latency 100
    Max latency so far: 1 microseconds.
    Max latency so far: 16 microseconds.
    Max latency so far: 50 microseconds.
    Max latency so far: 53 microseconds.
    Max latency so far: 83 microseconds.
    Max latency so far: 115 microseconds.

请注意：在这种特殊情况下，redis-cli 需要在您运行或计划运行 Redis 的服务器上运行，而不是在客户端上运行。在这种特殊模式下，redis-cli 根本不连接到 Redis 服务器：它只是尝试测量内核不提供 CPU 时间运行给 redis-cli 进程本身的最长时间。

在上面的示例中，系统的内在延迟仅为0.115毫秒（或115微秒），这是一个好消息，但请记住，内在延迟可能会随着系统负载的变化而改变。

虚拟化环境不会显示出很好的数字，尤其是在高负载或存在干扰邻居的情况下。以下是运行在Linode 4096实例上的Redis和Apache的运行情况：

    $ ./redis-cli --intrinsic-latency 100
    Max latency so far: 573 microseconds.
    Max latency so far: 695 microseconds.
    Max latency so far: 919 microseconds.
    Max latency so far: 1606 microseconds.
    Max latency so far: 3191 microseconds.
    Max latency so far: 9243 microseconds.
    Max latency so far: 9671 microseconds.

这里有一个固有的延迟为9.7毫秒：这意味着我们无法要求Redis提供更好的延迟。然而，在不同的虚拟化环境中以不同时间运行，负载较高或有嘈杂的邻居可能会显示出更糟糕的值。我们能够测量到最多40毫秒的延迟，尽管系统在其他方面表现正常。

由网络和通信引起的延迟

客户端通过TCP/IP连接或Unix域连接连接到Redis。
1 Gbit/s网络的典型延迟约为200微秒，而Unix域套接字的延迟可以低至30微秒。延迟实际上取决于您的网络和系统硬件。除了通信本身外，系统还会增加一些延迟（由于线程调度、CPU缓存、NUMA放置等原因）。在虚拟化环境中，系统引起的延迟显著高于物理机器。

后果是，即使Redis在亚微秒级别中处理大部分命令，但是客户端执行多次往返到服务器的操作仍需支付相关网络和系统延迟的代价。

高效的客户端将尝试通过将多个命令一起进行流水线处理来限制往返的次数。服务器和大多数客户端都完全支持这种处理方式。聚合命令，如MSET/MGET，也可以用于这个目的。从Redis 2.4开始，一些命令还支持可变参数，适用于所有数据类型。

以下是一些指南：

+ 如果您有能力，倾向于使用物理机来托管服务器，而不是虚拟机。
+ 不要系统化地连接/断开与服务器的连接（特别适用于基于Web的应用程序）。尽可能保持长连接。
+ 如果您的客户端位于与服务器相同的主机上，请使用Unix域套接字。
+ 倾向于使用聚合命令（MSET/MGET）或带有可变参数的命令（如果可能），而不是使用流水线。
+ 在流水线之前，如果可能的话，请使用流水线。
+ Redis支持Lua服务器端脚本，以覆盖不适合原始流水线的情况（例如，当一个命令的结果是后续命令的输入时）。

在Linux上，有些人可以通过调整进程的位置（taskset），cgroups，实时优先级（chrt），NUMA配置（numactl）或使用低延迟内核来实现更好的延迟。请注意，纯粹的Redis并不适合绑定在一个**单一** CPU 核心上。Redis可以派生后台任务，这些任务可能会消耗极高的CPU资源，例如`BGSAVE`或`BGREWRITEAOF`。这些任务绝不能在与主事件循环相同的核心上运行。

在大多数情况下，这类系统级优化是不需要的。
只有在必要的情况下才进行优化，并且只有在熟悉它们的情况下才进行优化。

Redis的单线程特性
-----------------

Redis使用*大部分* 单线程设计。这意味着一个进程为所有客户请求提供服务，使用一种称为 **多路复用** 的技术。这意味着Redis可以在任意给定的时刻处理一个请求，所以所有请求都是按顺序提供服务的。这与Node.js的工作方式非常相似。然而，这两个产品通常不被认为是慢的。这部分是由于完成单个请求所需的时间很短，但主要是因为这些产品被设计为不在系统调用上阻塞，如从套接字读取数据或写入数据。

我说Redis实际上是*大多数情况下*单线程的，自Redis 2.4开始，我们在Redis中使用线程来在后台执行一些缓慢的I/O操作，主要涉及磁盘I/O，但这并不改变Redis使用单个线程来处理所有请求的事实。

缓慢命令产生的延迟

作为单线程的后果，当一个请求处理缓慢时，所有其他客户端都必须等待这个请求被处理。当执行普通命令，如`GET`、`SET`或`LPUSH`时，这不是一个问题，因为这些命令的执行时间是恒定的（而且非常短）。然而，有一些操作涉及到多个元素的命令，如`SORT`、`LREM`、`SUNION`等。例如，计算两个大集合的交集可能需要相当长的时间。

所有命令的算法复杂度都已记录。一个好的做法是，在使用不熟悉的命令时系统地进行检查。

如果您担心延迟问题，您应该避免对由许多元素组成的值使用慢命令，或者您应该使用Redis复制运行一个副本，其中您运行所有慢查询。

使用Redis的Slow Log功能可以监控慢命令。

另外，您可以使用您喜爱的逐进程监控程序（例如 top、htop、prstat 等）快速检查主要 Redis 进程的 CPU 使用情况。如果在流量不高的情况下 CPU 使用率很高，通常意味着使用了较慢的命令。

**重要提示**：执行慢速命令导致的延迟的一个非常常见的来源是在生产环境中使用`KEYS`命令。根据Redis文档的说明，`KEYS`命令只应用于调试目的。自Redis 2.8起，引入了一些新的命令，以便逐步遍历键空间和其他大型集合，请查阅`SCAN`、`SSCAN`、`HSCAN`和`ZSCAN`命令获取更多信息。

fork产生的延迟

为了在后台生成RDB文件, 或者在启用AOF持久化时重写Append Only文件, Redis需要分叉后台进程.
分叉操作(在主线程中运行)本身可能导致延迟.

在大多数类Unix系统上，分叉操作是一项昂贵的操作，因为它涉及复制与进程相关联的许多对象。这对虚拟内存机制相关的页表尤其如此。

例如，在Linux/AMD64系统上，内存被划分为4 KB的页面。
为了将虚拟地址转换为物理地址，每个进程都存储一个页表（实际上表示为树），该表包含进程地址空间中每一页的至少一个指针。因此，一个大约24 GB的Redis实例需要一个大小为24 GB / 4 KB * 8 = 48 MB的页表。

在执行后台保存时，将必须进行分叉，这将涉及到分配和复制48 MB的内存。这需要时间和CPU资源，特别是在虚拟机中，分配和初始化大内存块可能是昂贵的。

在不同系统中的分叉时间
------------------------------

现代硬件在复制页面表方面非常快，但Xen不是这样。
Xen的问题不是与虚拟化相关，而是与Xen特定的。例如使用VMware或Virtual Box并不会导致fork时间变慢。
下面是一个比较不同Redis实例大小的fork时间的表格。数据是通过执行BGSAVE并查看INFO命令输出中的latest_fork_usec字段获得的。

然而好消息是，基于HVM的新型EC2实例在分叉时间方面要好得多，几乎与物理服务器持平，所以例如使用m3.medium（或更好）的实例将提供良好的结果。

* **在VMware上的Linux牛虚拟机** 6.0GB RSS分叉耗时77毫秒（每GB 12.8毫秒）。
* **在未知硬件上运行的Linux物理机** 6.1GB RSS分叉耗时80毫秒（每GB 13.1毫秒）。
* **在Xeon @ 2.27Ghz上运行的Linux物理机** 6.9GB RSS分叉耗时62毫秒（每GB 9毫秒）。
* **在6sync的KVM上的Linux虚拟机** 360 MB RSS分叉耗时8.2毫秒（每GB 23.3毫秒）。
* **在EC2上的旧实例类型的Linux虚拟机（Xen）** 6.1GB RSS分叉耗时1460毫秒（每GB 239.3毫秒）。
* **在EC2上的新实例类型的Linux虚拟机（Xen）** 1GB RSS分叉耗时10毫秒（每GB 10毫秒）。
* **在Linode上的Linux虚拟机（Xen）** 0.9GB RSS分叉耗时382毫秒（每GB 424毫秒）。

正如您所看到的，在Xen上运行的某些虚拟机存在性能损失，损失范围大约为一个数量级到两个数量级。对于EC2用户，建议很简单：使用基于最新HVM的实例。

透明巨大页引起的延迟

很不幸当Linux内核启用透明大页时，Redis在使用`fork`调用进行持久化到磁盘后会遇到很大的延迟惩罚。大页是以下问题的原因:

1. Fork被调用后，将创建两个共享巨页的进程。
2. 在繁忙的实例中，运行几个事件循环将导致命令定位到几千个页面，从而导致几乎整个进程内存的写时复制。
3. 这将导致很大的延迟和内存使用量。

请确保使用以下命令**禁用透明大页面**：

    echo never > /sys/kernel/mm/transparent_hugepage/enabled

由交换（操作系统分页）引起的延迟

Linux （和许多其他现代操作系统）能够将内存页面从内存移到磁盘，反之亦然，以便有效利用系统内存。

如果 Redis 页面被内核从内存移动到交换文件，当 Redis 使用存储在此内存页面中的数据（例如访问存储在此内存页面中的键）时，内核将停止 Redis 进程以将页面移回主内存。这是一个较慢的操作，涉及随机 I/O（与访问已在内存中的页面相比），将导致 Redis 客户端经历异常的延迟。

内核重新定位Redis内存页主要是由于三个原因：

* 由于运行中的进程需要的物理内存超过可用内存的数量，系统出现了内存压力。这个问题的最简例子就是Redis使用的内存超过了可用内存。
* Redis实例的数据集，或者数据集的一部分，大部分都是处于闲置状态（客户端从未访问过），因此内核可以将闲置的内存页换出到磁盘上。这个问题非常罕见，因为即使是相对较慢的实例也会经常访问所有内存页，迫使内核将所有页都保留在内存中。
* 一些进程在系统上产生大量的读或写I/O。由于文件通常被缓存，这往往会增加内核增加文件系统缓存的压力，从而产生交换活动。请注意这包括可以产生大型文件的Redis RDB和/或AOF后台线程。

幸运的是，Linux提供了很好的工具来解决这个问题，所以最简单的方法就是在怀疑出现交换导致的延迟时，只需要检查是否确实是这种情况。

第一件事是检查Redis内存交换到磁盘的数量。为了这样做，您需要获取Redis实例的pid：

    $ redis-cli info | grep process_id
    process_id:5454

现在进入此进程的/proc文件系统目录：

    $ cd /proc/5454

以下是一个名为**smaps**的文件，描述了Redis进程的内存布局（假设您使用的是Linux 2.6.16或更高版本）。
该文件包含有关我们进程内存映射的非常详细的信息，其中一个字段称为**Swap**，正是我们要寻找的内容。然而，smaps文件中并不只有一个交换字段，因为该文件包含了Redis进程的不同内存映射（进程的内存布局比简单的线性页面数组更复杂）。

由于我们对进程交换的所有内存都感兴趣，首先要做的是在所有文件中使用grep命令来查找交换字段（Swap field）：

    $ cat smaps | grep 'Swap:'
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                 12 kB
    Swap:                156 kB
    Swap:                  8 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  4 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  4 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  4 kB
    Swap:                  4 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB
    Swap:                  0 kB

如果一切都是0 kB，或者有零星的4k条目，那么一切都是正常的。实际上，在我们的示例实例（一个真正运行Redis并每秒为数百个用户提供服务的网站）中，有一些条目显示出更多交换的页面。为了调查这是否是一个严重的问题，我们改变我们的命令，以便还打印内存映射的大小：

    $ cat smaps | egrep '^(Swap|Size)'
    Size:                316 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB
    Size:                  8 kB
    Swap:                  0 kB
    Size:                 40 kB
    Swap:                  0 kB
    Size:                132 kB
    Swap:                  0 kB
    Size:             720896 kB
    Swap:                 12 kB
    Size:               4096 kB
    Swap:                156 kB
    Size:               4096 kB
    Swap:                  8 kB
    Size:               4096 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB
    Size:               1272 kB
    Swap:                  0 kB
    Size:                  8 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB
    Size:                 16 kB
    Swap:                  0 kB
    Size:                 84 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB
    Size:                  8 kB
    Swap:                  4 kB
    Size:                  8 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  4 kB
    Size:                144 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  4 kB
    Size:                 12 kB
    Swap:                  4 kB
    Size:                108 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB
    Size:                272 kB
    Swap:                  0 kB
    Size:                  4 kB
    Swap:                  0 kB

如您从输出中可以看到，有一个720896 kB的映射（只有12 kB被交换），另有另一个映射中交换了156 kB：
基本上我们的内存只交换了很少的部分，所以这不会造成任何问题。

如果非常量的进程内存被交换到磁盘上，那么您的延迟问题很可能与交换有关。如果这是您的Redis实例的情况，您可以使用 **vmstat** 命令进一步验证：

    $ vmstat 1
    procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
     r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
     0  0   3980 697932 147180 1406456    0    0     2     2    2    0  4  4 91  0
     0  0   3980 697428 147180 1406580    0    0     0     0 19088 16104  9  6 84  0
     0  0   3980 697296 147180 1406616    0    0     0    28 18936 16193  7  6 87  0
     0  0   3980 697048 147180 1406640    0    0     0     0 18613 15987  6  6 88  0
     2  0   3980 696924 147180 1406656    0    0     0     0 18744 16299  6  5 88  0
     0  0   3980 697048 147180 1406688    0    0     0     4 18520 15974  6  6 88  0
    ^C

对我们的需求来说，输出中有趣的部分是两列**si**和**so**，它们统计了从/到交换文件中交换的内存量。如果你在这两列中看到非零计数，那么你的系统中存在交换活动。

最后，可以使用 **iostat** 命令来检查系统的全局 I/O 活动。

    $ iostat -xk 1
    avg-cpu:  %user   %nice %system %iowait  %steal   %idle
              13.55    0.04    2.92    0.53    0.00   82.95

    Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util
    sda               0.77     0.00    0.01    0.00     0.40     0.00    73.65     0.00    3.62   2.58   0.00
    sdb               1.27     4.75    0.82    3.54    38.00    32.32    32.19     0.11   24.80   4.24   1.85

如果您的延迟问题是由于 Redis 内存被交换到磁盘上造成的，则需要降低系统中的内存压力，可以通过增加可用内存来缓解，或者避免在同一系统中运行其他内存占用较高的进程。

由于AOF和磁盘I/O引起的延迟

另一个延迟源是由于Redis上的追加只文件支持。 AOF基本上使用两个系统调用来完成其工作。 其中一个是write（2），用于将数据写入追加只文件，另一个是fdatasync（2），用于刷新内核文件缓冲区，以确保用户指定的持久性级别。

write(2)和fdatasync(2)调用都可能是延迟的原因。
例如，当系统在进行全局同步时，write(2)可能会阻塞；或者当输出缓冲区满了并且内核需要刷新到磁盘以接受新的写入时，也可能会阻塞。

`fdatasync（2）`调用是延迟的主要来源，因为在许多不同的内核和文件系统组合上，它可能需要几毫秒甚至几秒的时间来完成，特别是在其他进程进行输入/输出的情况下。因此，Redis 2.4以后的版本中，为了尽可能避免这种情况，Redis将`fdatasync（2）`调用放在不同的线程中执行。

我们将看到配置如何影响使用AOF文件时的延迟量和源。

AOF 可以通过使用**appendfsync**配置选项以三种不同的方式配置在磁盘上执行 fsync 的操作（此设置可通过使用 **CONFIG SET** 命令在运行时进行修改）。

* 当将`appendfsync`参数设置为**no**时，Redis将不会执行`fsync`操作。
在这种配置下，延迟的唯一来源就是`write(2)`操作。
当发生这种情况时，通常没有解决办法，因为磁盘无法跟上Redis接收数据的速度，不过如果磁盘没有被其他进行I/O操作的进程严重拖慢，这种情况并不常见。

* 当appendfsync 设置为**everysec**时，Redis每秒执行一次fsync操作。它使用一个不同的线程，如果fsync操作仍在进行中，Redis会使用一个缓冲区来延迟write(2)调用长达两秒（因为在Linux上，如果针对同一文件还有fsync操作正在进行，write将被阻塞）。然而，如果fsync操作时间过长，Redis最终会执行write(2)调用，即使fsync操作仍在进行中，这可能会导致延迟问题。

* 当`appendfsync`设置为**always**时，在每次写入操作之前，会执行一次`fsync`，然后才向客户端返回OK代码（实际上Redis会尝试将多个同时执行的命令集中到一个`fsync`中）。在这种模式下，性能通常非常低，强烈建议使用快速的磁盘和可以在短时间内执行`fsync`操作的文件系统实现。

大多数Redis用户将使用**no**或**everysec**设置的appendfsync配置指令。最小延迟的建议是避免其他进程在同一系统中进行输入/输出。使用SSD硬盘也有所帮助，但通常即使非SSD硬盘在Redis将数据写入append only文件而无需执行任何寻址时也能表现出良好的性能，但前提是磁盘是空闲的。

如果您想调查与附加文件相关的延迟问题，您可以在Linux下使用strace命令：

    sudo strace -p $(pidof redis-server) -T -e trace=fdatasync

上述命令将显示Redis在主线程中执行的所有fdatasync(2)系统调用。使用上述命令，您将无法看到在将appendfsync配置选项设置为**everysec**时后台线程执行的fdatasync系统调用。为了这样做，只需在strace命令后添加-f开关。

如果你愿意，你也可以使用以下命令查看fdatasync和write系统调用：

    sudo strace -p $(pidof redis-server) -T -e trace=fdatasync,write

然而，由于write（2）也用于向客户端套接字写入数据，因此这可能会显示与磁盘I / O无关的太多内容。
显然，没有办法告诉strace只显示慢系统调用，因此我使用以下命令：

    sudo strace -f -p $(pidof redis-server) -T -e trace=fdatasync,write 2>&1 | grep -v '0.0' | grep -v unfinished

超时导致的延迟

Redis以两种方式删除过期的键：

1. Lazily 删除: 延迟删除机制会在访问键时检查其是否过期，如果过期则删除。
2. 主动删除：定期任务会主动扫描数据库，找出过期键并删除。

+ 当一个键被命令请求时，如果发现它已经过期了，一种**懒惰**的方法是使其过期。
+ 当每过100毫秒，一种**主动**的方法是使一些键过期。

活跃过期的设计是自适应的。每100毫秒（每秒10次）启动一个过期周期，并执行以下操作：

+ 样本 `ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP` 键，清除所有已过期的键。
+ 如果超过25％的键已过期，则重复执行。

考虑到默认情况下`ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP`设置为20，并且每秒执行十次该过程，通常每秒只会主动过期200个键。即使长时间不访问已过期键，这足以使数据库快速清理，以便* 懒惰 *算法不起作用。同时，每秒只删除200个键对Redis实例的延迟没有影响。

然而，该算法具有自适应性，如果在抽样键集中发现超过25%的键已经过期，它将循环。但是考虑到我们每秒运行算法十次，这意味着在*同一秒内*，我们随机抽样的键集中超过25%的键不幸地过期。

基本上，这意味着**如果数据库在同一秒钟有很多很多个过期的键，而这些键至少占当前设置了过期时间的键的25%**，Redis 可能会阻塞，以使已过期的键的百分比低于25%。

为了避免使用太多内存存储已过期的键，需要采用这种方法。通常来说，这是绝对安全的，因为在同一秒钟内将过期的键数量很少，但用户使用相同的 Unix 时间频繁执行 `EXPIREAT` 操作也不是不可能。

简而言之：请注意，许多在同一时刻过期的密钥可能会导致延迟。

Redis软件看门狗
---

Redis 2.6引入了*Redis软件狗（软件看门狗）*，它是一个调试工具，旨在跟踪那些由于某种原因而无法使用普通工具进行分析的延迟问题。

软件看门狗是一个实验性的功能。虽然它被设计用于生产环境，但在继续之前应该备份数据库，因为它可能会与Redis服务器的正常执行产生意外的交互。

当其他方法无法追踪问题时，只有在万不得已的情况下才使用它。

这是功能的工作原理：

* 用户使用`CONFIG SET`命令启用软件看门狗。
* Redis开始持续监控自身。
* 如果Redis检测到服务器在某个操作中被阻塞，且返回速度不够快，可能是导致延迟问题的源头，将在日志文件中转储有关服务器被阻塞位置的低级报告。
* 用户在Redis Google Group中联系开发者，包括看门狗报告在消息中。

请注意，此功能无法通过`redis.conf`文件启用，因为它仅可以在已经运行的实例中启用，并且仅供调试目的使用。

要启用此功能，请使用以下内容：

    CONFIG SET watchdog-period 500

该周期以毫秒为单位指定。在上述示例中，我指定仅在服务器检测到500毫秒或更长延迟时记录延迟问题。最小可配置周期为200毫秒。

当您完成软件看门狗的使用后，可以将`watchdog-period`参数设置为0来关闭它。**重要提示：**请务必记住这一点，因为将实例的看门狗保持开启的时间超过必要时间通常不是一个好主意。

以下是软件看门狗检测到超过预配置延迟的日志文件打印示例：

    [8547 | signal handler] (1333114359)
    --- WATCHDOG TIMER EXPIRED ---
    /lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]
    /lib/libpthread.so.0(+0xf8f0) [0x7f16b5f158f0]
    /lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]
    /lib/libc.so.6(usleep+0x34) [0x7f16b5c62844]
    ./redis-server(debugCommand+0x3e1) [0x43ab41]
    ./redis-server(call+0x5d) [0x415a9d]
    ./redis-server(processCommand+0x375) [0x415fc5]
    ./redis-server(processInputBuffer+0x4f) [0x4203cf]
    ./redis-server(readQueryFromClient+0xa0) [0x4204e0]
    ./redis-server(aeProcessEvents+0x128) [0x411b48]
    ./redis-server(aeMain+0x2b) [0x411dbb]
    ./redis-server(main+0x2b6) [0x418556]
    /lib/libc.so.6(__libc_start_main+0xfd) [0x7f16b5ba1c4d]
    ./redis-server() [0x411099]
    ------

注意：在示例中，使用了**DEBUG SLEEP**命令来阻塞服务器。如果服务器在不同的上下文中被阻塞，堆栈跟踪将不同。

如果你恰好收集到多个看门狗堆栈跟踪，我们鼓励你将所有内容发送到Redis Google Group：我们获取的跟踪越多，就越容易理解你的实例问题所在。
