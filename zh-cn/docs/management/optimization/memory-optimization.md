---
title: 内存优化
linkTitle: 内存优化
description: 优化Redis内存使用的策略
weight: 1
aliases: [
    /topics/memory-optimization,
    /docs/reference/optimization/memory-optimization
]
---

## 小聚合数据类型的特殊编码

自从Redis 2.2版本以来，许多数据类型都进行了优化，以在一定大小的范围内占用更少的空间。
哈希、只由整数组成的列表、集合和有序集合，当其元素数量较小并且大小不超过一定值时，会被编码成一种非常节省内存的方式，使用的内存可以少至原来的*十分之一*（平均节省内存为原来的五分之一）。

这对用户和API来说是完全透明的。
由于这是一个CPU / 内存的权衡，可以使用以下redis.conf指令来调整特殊编码类型的最大元素数量和最大元素大小（显示了默认值）：

### Redis <= 6.2

```
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
zset-max-ziplist-entries 128 
zset-max-ziplist-value 64
set-max-intset-entries 512
```

### Redis >= 7.0

```
hash-max-listpack-entries 512
hash-max-listpack-value 64
zset-max-listpack-entries 128
zset-max-listpack-value 64
set-max-intset-entries 512
```

### Redis >= 7.2

以下指令也可用：

```
set-max-listpack-entries 128
set-max-listpack-value 64
```

如果一个特殊编码的值超过了配置的最大大小，
Redis 将自动将其转换为正常编码。
对于小型值，这个操作非常快，
但如果你改变了设置以便使用特殊编码的值来存储更大的聚合类型，
建议运行一些基准测试来检查转换时间。

## 使用32位实例


将Redis编译为32位目标时，由于指针较小，每个键使用的内存要少得多，但此类实例的最大内存使用量将限制为4 GB。
要将Redis编译为32位二进制文件，请使用 *make 32bit* 命令。
RDB和AOF文件在32位和64位实例之间兼容
（当然还兼容大小端），因此您可以在32位和64位之间切换，或者反之，而不会出现问题。

## 位和字节级操作

Redis 2.2引入了新的位和字节级操作：`GETRANGE`，`SETRANGE`，`GETBIT`和`SETBIT`。
使用这些命令，您可以将Redis字符串类型视为随机访问数组。
例如，如果您有一个应用程序，用户通过唯一的递增整数编号进行标识，
您可以使用位图来保存关于用户订阅邮件列表的信息，设置已订阅的位并清除未订阅的位，或者反之亦然。
对于1亿用户，这些数据在Redis实例中仅占用12兆字节的RAM。
您也可以使用`GETRANGE`和`SETRANGE`来为每个用户存储一字节的信息。
这只是一个示例，但使用这些新的原语可以在非常小的空间中建模多个问题。

## 如果可能的话，请使用井号


小型哈希在非常小的空间中编码，因此尽量使用哈希来表示数据。
例如，如果你在一个Web应用程序中有表示用户的对象，
不要使用不同的键来表示名字、姓氏、电子邮件、密码，而是使用一个包含所有必需字段的单个哈希。

如果您想了解更多信息，请阅读下一节。

## 使用哈希在Redis上构建一个非常高效的键值存储库

基本上可以使用Redis模拟一个简单的键值存储，其中值可以只是字符串，比纯Redis键更内存高效，也比memcached更内存高效。

从一些事实开始：一些键比一个包含几个字段的哈希键使用更多内存。这是如何可能的呢？我们使用了一个诀窍。
理论上，为了保证我们在常数时间内执行查找（也称为大O符号中的O(1)），需要使用一个在平均情况下具有常数时间复杂度的数据结构，比如哈希表。

但很多时候哈希表只包含一些字段。当哈希表较小时，我们可以将它们编码为O(N)的数据结构，例如具有以长度为前缀的键值对的线性数组。由于只有在N较小时才会这样做，所以`HGET`和`HSET`命令的摊还时间仍然是O(1)：一旦包含元素的数量过多（可以在redis.conf中配置限制），哈希表将被转换为实际的哈希表。

这不仅在时间复杂度的角度上工作得很好，而且在常数时间上也表现得很好，因为线性的键值对数组与CPU缓存非常匹配（在缓存局部性方面比哈希表更好）。

然而，由于哈希字段和值并不总是表示为完整的 Redis 对象，哈希字段不能像真正的键一样具有关联的存活时间（过期），且只能包含字符串。但我们对此没有问题，这也是设计哈希数据类型 API 的初衷（我们更相信简单性而非功能性，因此不允许嵌套数据结构，也不允许单个字段的过期时间）。

哈希是内存效率高的。当使用哈希来表示对象或者在有一组相关字段的情况下建模其他问题时，这非常有用。但是如果我们只有一个简单的键值业务呢？

想象一下，我们想要使用Redis作为缓存来存储许多小对象，这些对象可以是JSON编码的对象、小的HTML片段、简单的键->布尔值等等。基本上，任何东西都可以是一个字符串->字符串的映射，具有小的键和值。

现在假设我们想要缓存的对象是按编号排列的，如下所示：

 * object:102393
 * object:1234
 * object:5

以下是我们可以做的。每次执行SET操作设置新值时，实际上会将键分为两部分，一部分用作键，另一部分用作哈希的字段名。例如，名为"object:1234"的对象实际上被分割为：

* 一个名为object的键: 12
* 一个名为34的字段

如此，我们使用除了最后两个字符外的所有字符作为键，最后两个字符作为哈希字段名称。要设置我们的键，我们使用以下命令：

```
HSET object:12 34 somevalue
```

正如您所看到的，每个哈希都将包含100个字段，这是在CPU和内存节省之间的最佳平衡。

还有一件重要的事情需要注意，在这个架构中
无论我们缓存了多少个对象，每个哈希都会拥有大约100个字段。这是因为我们的对象总是以数字结尾，而不是随机字符串。某种程度上，最后的数字可以被视为隐式的预分片形式。

小数怎么办？比如对象：2？我们使用“对象：”作为键名，使用整个数字作为哈希字段名来处理这种情况。所以，对象：2和对象：10都会被存储在键“对象：”中，但一个的字段名是“2”，另一个是“10”。

以这种方式我们能省下多少内存呢？

我使用下面的Ruby程序来测试这个工作的原理：

```ruby
require 'rubygems'
require 'redis'

USE_OPTIMIZATION = true

def hash_get_key_field(key)
  s = key.split(':')
  if s[1].length > 2
    { key: s[0] + ':' + s[1][0..-3], field: s[1][-2..-1] }
  else
    { key: s[0] + ':', field: s[1] }
  end
end

def hash_set(r, key, value)
  kf = hash_get_key_field(key)
  r.hset(kf[:key], kf[:field], value)
end

def hash_get(r, key, value)
  kf = hash_get_key_field(key)
  r.hget(kf[:key], kf[:field], value)
end

r = Redis.new
(0..100_000).each do |id|
  key = "object:#{id}"
  if USE_OPTIMIZATION
    hash_set(r, key, 'val')
  else
    r.set(key, 'val')
  end
end
```

这是对 Redis 2.2 的 64 位实例的结果：

* USE_OPTIMIZATION 设置为 true：使用了 1.7 MB 的内存
* USE_OPTIMIZATION 设置为 false：使用了 11 MB 的内存

这是一个数量级的订单，我认为这使得Redis在一定程度上成为了最高效的内存键值存储之一。

*警告*：为了使其正常工作，请确保在您的redis.conf文件中有类似以下的配置：

```
hash-max-zipmap-entries 256
```

还要记得将以下字段设置为相应密钥和值的最大尺寸：

```
hash-max-zipmap-value 1024
```

每次哈希超过指定的元素数量或元素大小时，
它将被转换为真正的哈希表，从而丧失了内存的节约。

你可能会问，为什么不在通常的键空间中隐含地进行这样的操作，这样我就不用担心了？有两个原因：一是我们倾向于明确地进行权衡，而这是很多方面的明显权衡：CPU、内存和最大元素大小。第二个原因是顶层键空间必须支持很多有趣的事情，如过期、LRU数据等等，因此一般方式不实用。

但是 Redis 的方式是用户必须理解事物是如何工作的，以便能够选择最好的折衷方案并理解系统将会如何行为。

## 内存分配

为了存储用户键，Redis分配的内存最多与`maxmemory`设置允许的内存相同（但也可能有一些额外的分配）。

精确值可以在配置文件中设定，或者稍后通过`CONFIG SET`进行设置（更多信息，请参见[使用内存作为LRU缓存](/docs/reference/eviction)）。关于Redis如何管理内存，有几点需要注意的地方：

* Redis在键被删除时不总是会将内存（返回）释放给操作系统。
这不是Redis特有的问题，而是大多数malloc()实现的常态。
例如，如果你在一个实例中填充了5GB的数据，然后删除了相当于2GB的数据，
进程的Resident Set Size（也称为RSS，即进程消耗的内存页面数）
可能仍然在5GB左右，即使Redis声称用户内存只有大约3GB。这是因为底层分配器无法轻松释放内存。
例如，通常大多数被删除的键被分配在与仍然存在的其他键相同的页面上。
* 前面的观点意味着您需要根据您的**内存使用峰值**来配置内存。如果您的工作负载需要10GB的内存，即使大部分时间只需要5GB，您也需要配置10GB的内存。
* 然而，分配器是聪明的，能够重用空闲的内存块，因此在释放了5GB数据集中的2GB后，当您再次开始添加更多的键时，
您会看到RSS（Resident Set Size）保持稳定，不再增长，
因为您新增了最多2GB的附加键时，分配器基本上尝试重用先前（逻辑上）释放的2GB内存。
* 因为所有这些，当您的内存使用峰值远大于当前使用的内存时，碎片化比率是不可靠的。
碎片化比率计算为实际使用的物理内存（RSS值）除以当前使用的内存量（即Redis执行的所有分配的总和）。
由于RSS反映了内存峰值，当（虚拟上）使用的内存较低，因为许多键/值被释放，但RSS较高时，比率`RSS / mem_used`将非常高。

如果未设置 `maxmemory`，Redis 将会根据需要分配内存，从而可能逐渐占用所有可用内存。因此，通常建议配置一些限制。您可能还希望将 `maxmemory-policy` 设置为 `noeviction`（这在一些较旧的 Redis 版本中不是默认值）。

这使得Redis在达到限制时返回内存不足的错误，进而可能导致应用程序错误，但不会因为内存饥饿而使整个机器崩溃。
