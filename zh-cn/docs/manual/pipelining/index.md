---
title: "Redis pipelining"
linkTitle: "Pipelining"
weight: 2
description: 如何通过批处理Redis命令来优化往返时间
aliases:
  - /topics/pipelining
---

Redis管道化是一种通过一次性发出多个命令而无需等待每个命令的响应来提高性能的技术。大多数Redis客户端都支持管道化。本文档描述了管道化旨在解决的问题以及Redis中的管道化工作原理。

## 请求/响应协议和往返时间（RTT）

Redis 是一个使用客户端-服务器模型的 TCP 服务器，采用了请求/响应的协议。

这意味着通常一个请求需要经过以下步骤完成:

* 客户端向服务器发送查询，并从套接字读取，通常以阻塞方式等待服务器响应。
* 服务器处理命令并将响应发送回客户端。

所以，例如四个命令的顺序是这样的：

* *客户端:* INCR X
 * *服务器:* 1
 * *客户端:* INCR X
 * *服务器:* 2
 * *客户端:* INCR X
 * *服务器:* 3
 * *客户端:* INCR X
 * *服务器:* 4

客户端和服务器通过网络连接。
这种连接可以非常快（回环接口）或者非常慢（通过互联网在两个主机之间建立连接）。
无论网络延迟是多少，数据包从客户端到服务器的传输以及服务器回复到客户端都需要时间。

这个时间被称为RTT（往返时间）。
很容易看出当一个客户端需要连续执行许多请求时，这会影响性能（比如往同一个列表添加许多元素，或者用许多键值填充数据库）。
例如，如果RTT时间为250毫秒（在互联网上速度非常慢的情况下），即使服务器能够每秒处理100k个请求，我们每秒最多只能处理四个请求。

如果使用的接口是环回接口，则RTT会更短，通常为亚毫秒级别，但即使如此，如果您需要连续执行许多写操作，这也会累计很多。

幸运的是，有一种方法可以改善这种使用情况。

## Redis 管道传输

可以实现请求/响应服务器，即使客户端尚未读取旧的响应也能处理新的请求。
这样可以向服务器发送*多个命令*而无需等待任何回复，最后一次性读取回复。

这被称为流水线处理，并且是一种长期以来广泛使用的技术。
例如，许多POP3协议的实现已经支持此功能，大大加快了从服务器下载新电子邮件的过程。

自Redis的早期版本起，就支持流水线技术，所以无论您使用的是哪个版本，都可以在Redis中使用流水线技术。
下面是使用原始的netcat实用工具的示例：

```bash 
$ (printf "PING\r\nPING\r\nPING\r\n"; sleep 1) | nc localhost 6379
+PONG
+PONG
+PONG
```

这次我们不会为每个呼叫支付RTT的成本，而是只需为三个命令支付一次成本。

为了明确起见，使用流水线技术，我们第一个示例的操作顺序将如下所示：

* *客户端:* INCR X
 * *客户端:* INCR X
 * *客户端:* INCR X
 * *客户端:* INCR X
 * *服务器:* 1
 * *服务器:* 2
 * *服务器:* 3
 * *服务器:* 4

**重要提示**：虽然客户端使用管道传输命令，但服务器将被迫在内存中排队响应。因此，如果您需要使用管道发送大量命令，最好将它们分批发送，每个批次包含合理数量的命令，例如10,000个命令，读取响应，然后再发送另外10,000个命令，依此类推。速度几乎相同，但额外使用的内存最多只是为这10,000个命令排队响应所需的量。

## 这不仅仅是RTT的问题

流水线不仅是减少与往返时间相关的延迟成本的方法，它实际上极大地提高了在给定Redis服务器中每秒执行的操作数量。
这是因为如果不使用流水线，从访问数据结构和生成响应的角度来看，为每个命令提供服务是非常廉价的，但从进行套接字I / O的角度来看却非常昂贵。这涉及调用`read()`和`write()`系统调用，这意味着从用户空间切换到内核空间。
上下文切换是一个巨大的速度惩罚。

当使用流水线处理时，通常会使用一个`read()`系统调用来读取多个命令，并使用一个`write()`系统调用来传送多个回复。因此，每秒执行的查询总数最初几乎线性增加，随着流水线的长度增加，最终达到了没有流水线的基准查询执行次数的10倍，如图所示。

![管道大小和IOPs](pipeline_iops.png)

## 一个真实世界的代码示例


在下面的基准测试中，我们将使用支持管道传输的Redis Ruby客户端来测试由于管道传输而导致的速度提升：

```ruby
require 'rubygems'
require 'redis'

def bench(descr)
  start = Time.now
  yield
  puts "#{descr} #{Time.now - start} seconds"
end

def without_pipelining
  r = Redis.new
  10_000.times do
    r.ping
  end
end

def with_pipelining
  r = Redis.new
  r.pipelined do
    10_000.times do
      r.ping
    end
  end
end

bench('without pipelining') do
  without_pipelining
end
bench('with pipelining') do
  with_pipelining
end
```

运行上述简单脚本在我的Mac OS X系统上得到以下数据，通过回环接口运行，其中流水线处理将提供最小的改善，因为RTT已经相当低：

```
without pipelining 1.185238 seconds
with pipelining 0.250783 seconds
```
正如您所看到的，通过使用管道化，我们将传输速度提高了五倍。

## 管道化 vs 脚本化

使用自2.6版起可用的[Redis脚本](/commands/eval)，可以更有效地解决一些需要在服务器端执行大量工作的管道使用案例。
脚本的一个巨大优势是能够以最小的延迟读取和写入数据，使得像*读取、计算、写入*这样的操作非常快速（在这种情况下，管道无法帮助，因为客户端需要在调用写入命令之前获得读取命令的回复）。

有时应用程序可能还想在管道中发送EVAL或EVALSHA命令。
这是完全可能的，Redis通过[SCRIPT LOAD](https://redis.io/commands/script-load)命令显式支持它（保证可以调用EVALSHA而不会失败）。

## 附录：为什么忙等待循环在回环接口上也很慢？

即使在这个页面中提及的所有背景已经覆盖，当在回环接口中执行以下Redis基准测试（伪代码）时，你仍然会想知道为什么它会慢，尽管服务器和客户端在同一台物理机上运行：

```sh
FOR-ONE-SECOND:
    Redis.SET("foo","bar")
END
```

毕竟，如果Redis进程和基准测试都在同一台机器上运行，那么它只是在内存中从一个位置复制消息到另一个位置，没有任何实际的延迟或网络参与吗？

原因是系统中的进程并不总是在运行，实际上是内核调度程序让进程运行。
例如，当允许基准测试运行时，它会从Redis服务器读取回复（与执行的最后一个命令相关），并写入新命令。
该命令现在在回环接口缓冲区中，但为了被服务器读取，内核应该调度服务器进程（当前在系统调用中被阻塞）运行，依此类推。
因此，在实际环境中，回环接口仍然具有类似网络的延迟，这是由内核调度程序的工作方式造成的。

基本上，当在网络服务器上测试性能时，忙循环基准测试是可以做的最愚蠢的事情之一。明智的做法是避免以这种方式进行基准测试。
