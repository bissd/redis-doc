---
title: "使用Redis进行分布式锁"
linkTitle: "分布式锁"
weight: 1
description: >
    一个使用Redis的分布式锁模式
aliases: [
    /topics/distlock,
    /docs/reference/patterns/distributed-locks,
    /docs/reference/patterns/distributed-locks.md
]
---
分布式锁在许多环境中都是非常有用的原语，当不同的进程必须以互斥的方式使用共享资源时。

有许多库和博文介绍了如何使用Redis实现DLM（分布式锁管理器），但每个库都使用不同的方法，而且许多库使用简单的方法，相比稍微复杂一点的设计，可以获得更低的保证。

本页面描述了一种更标准的算法来使用Redis实现分布式锁。我们提出了一种名为**Redlock**的算法，它实现了一个我们认为比普通单实例方法更安全的DLM（分布式锁管理器）。我们希望社区能够对其进行分析、提供反馈，并将其作为实现或更复杂或替代设计的起点。

## 实现方式

在描述算法之前，这里有一些现有的实现链接，可以用作参考。

* [Redlock-rb](https://github.com/antirez/redlock-rb)（Ruby实现）。还有一个[Redlock-rb的分支](https://github.com/leandromoreira/redlock-rb)，它添加了一个用于简化分发的gem。
* [Redlock-py](https://github.com/SPSCommerce/redlock-py)（Python实现）。
* [Pottery](https://github.com/brainix/pottery#redlock)（Python实现）。
* [Aioredlock](https://github.com/joanvila/aioredlock)（Asyncio Python实现）。
* [Redlock-php](https://github.com/ronnylt/redlock-php)（PHP实现）。
* [PHPRedisMutex](https://github.com/malkusch/lock#phpredismutex)（进一步的PHP实现）。
* [cheprasov/php-redis-lock](https://github.com/cheprasov/php-redis-lock)（用于锁的PHP库）。
* [rtckit/react-redlock](https://github.com/rtckit/reactphp-redlock)（Async PHP实现）。
* [Redsync](https://github.com/go-redsync/redsync)（Go实现）。
* [Redisson](https://github.com/mrniko/redisson)（Java实现）。
* [Redis::DistLock](https://github.com/sbertrang/redis-distlock)（Perl实现）。
* [Redlock-cpp](https://github.com/jacket-code/redlock-cpp)（C++实现）。
* [Redis-plus-plus](https://github.com/sewenew/redis-plus-plus/#redlock)（C++实现）。
* [Redlock-cs](https://github.com/kidfashion/redlock-cs)（C#/.NET实现）。
* [RedLock.net](https://github.com/samcook/RedLock.net)（C#/.NET实现）。包括异步和锁扩展支持。
* [ScarletLock](https://github.com/psibernetic/scarletlock)（可配置的C# .NET实现）。
* [Redlock4Net](https://github.com/LiZhenNet/Redlock4Net)（C# .NET实现）。
* [node-redlock](https://github.com/mike-marcacci/node-redlock)（NodeJS实现）。包括锁扩展支持。
* [Deno DLM](https://github.com/oslabs-beta/Deno-Redlock)（Deno实现）。
* [Rslock](https://github.com/hexcowboy/rslock)（Rust实现）。包括异步和锁扩展支持。

## 安全性和活性保证

我们将使用仅有三个属性来对我们的设计建模，从我们的角度来看，这些属性是使用分布式锁的有效方式所需的最低保证。

1. 安全属性：互斥。在任何给定时刻，只有一个客户端能持有锁。
2. 存活性属性 A：无死锁。最终始终可以获取到锁，即使锁资源的客户端崩溃或发生分区。
3. 存活性属性 B：容错性。只要大部分 Redis 节点正常运行，客户端就能够获取和释放锁。

## 为什么仅基于故障转移的实现还不够

为了理解我们想要改进的内容，让我们分析一下大多数基于Redis的分布式锁库的当前状况。

使用Redis锁定资源的最简单方法是在一个实例中创建一个键。通常情况下，使用Redis的过期特性来创建一个带有限时存活的键，以便最终会被释放（我们列表中的属性2）。当客户端需要释放资源时，它删除该键。

表面上看这个工作得不错，但有一个问题：这是我们架构中的单点故障。如果 Redis 主节点出现故障会怎么样？
好吧，我们添加一个副本！如果主节点不可用，就使用它。但很遗憾，这是不可行的。这样做将无法实现我们的互斥安全属性，因为 Redis 复制是异步的。

这个模型存在竞态条件：

1. 客户端 A 在主服务器上获取锁。
2. 主服务器在将键的写入传输到副本之前崩溃。
3. 副本被提升为主服务器。
4. 客户端 B 获取了与资源 A 已经持有锁的相同资源的锁。**安全违规！**

有时在特殊情况下（例如在故障期间），允许多个客户端同时持有锁是可以接受的。
如果是这种情况，你可以使用基于复制的解决方案。否则，我们建议按照本文档中描述的解决方案来实施。

## 通过单个实例实现的正确方式

在尝试克服上述单实例设置的限制之前，让我们来了解一下在这种简单情况下如何正确地进行操作，因为在一些应用中，偶尔出现竞态条件是可接受的，而且因为将单实例锁定是我们将在此描述的分布式算法的基础。

获得锁的方法如下：

        SET resource_name my_random_value NX PX 30000

下面是所有数据，不要把它当作命令来处理：

如果键不存在，该命令将设置键（`NX` 选项），并在30000毫秒后过期（`PX` 选项）。
键被设置为值“my_random_value”。该值在所有客户端和所有锁请求中必须是唯一的。

基本上，随机值用于以安全的方式释放锁定，通过一个告诉Redis的脚本：仅当存在该键且存储在键上的值恰好是我期望的值时，删除该键。这是通过以下Lua脚本实现的：

    if redis.call("get",KEYS[1]) == ARGV[1] then
        return redis.call("del",KEYS[1])
    else
        return 0
    end

这非常重要，以避免删除由其他客户端创建的锁定。例如，一个客户端可能获得锁定，在执行某些操作时被阻塞的时间超过了锁定的有效时间（键将过期的时间），然后删除锁定，而该锁已经被其他客户端获取。
仅使用`DEL`不安全，因为一个客户端可能删除另一个客户端的锁定。与上述脚本相反，每个锁定都使用随机字符串“签名”，因此仅当仍然是尝试删除它的客户端设置的那个锁定时，才会删除该锁定。

这个随机字符串应该是什么？我们假设它是从`/dev/urandom`获取的20个字节，但您可以找到更便宜的方法使其足够独特以满足您的任务需求。
例如，一个安全的选择是使用`/dev/urandom`作为种子来初始化RC4，并从中生成一个伪随机流。
一个更简单的解决方案是使用具有微秒精度的UNIX时间戳，将时间戳与客户端ID连接在一起。虽然不太安全，但对于大多数环境来说可能足够了。

"锁的有效时间"是我们用作密钥存活时间的时间。它既是自动释放时间，也是客户端在另一个客户端可以再次获取锁之前执行所需操作的时间。这在技术上不违反互斥保证，该保证仅限于从获取锁的瞬间开始的一段给定时间窗口内。

所以现在我们有了一种很好的获取和释放锁的方法。通过这个系统，对于由单个始终可用实例组成的非分布式系统的推理是安全的。让我们将这个概念扩展到一个没有这些保证的分布式系统上。

## Redlock算法

在分布式版本的算法中，我们假设存在N个Redis主节点。这些节点是完全独立的，因此我们不使用复制或任何其他隐式的协调系统。我们已经描述了如何在单个实例中安全地获取和释放锁定。我们默认算法将使用此方法在单个实例中获取和释放锁定。在我们的示例中，我们将N设置为5，这是一个合理的值，因此我们需要在不同的计算机或虚拟机上运行5个Redis主节点，以确保它们以大部分独立的方式失败。

为了获得锁定，客户端执行以下操作：

1. 它获取当前时间的毫秒数。
2. 它按顺序尝试在所有的N个实例中使用相同的键名和随机值获取锁定。在第2步中，在每个实例中设置锁定时，客户端使用相对于总锁自动释放时间很小的超时时间进行获取。例如，如果自动释放时间为10秒，则超时时间可能在~5-50毫秒的范围内。这样做可以防止客户端因尝试与Redis节点通信而长时间被阻塞：如果一个实例不可用，我们应该尽快尝试与下一个实例通信。
3. 客户端通过从当前时间中减去第1步获得的时间戳来计算获得锁定所花费的时间。仅当客户端能够在大多数实例（至少3个）中获得锁定，并且获得锁定所花费的总时间小于锁定的有效时间时，才认为锁定已获得。
4. 如果成功获得锁定，则其有效时间被认为是初始有效时间减去在第3步中计算得到的时间花费。
5. 如果由于某种原因客户端无法获取锁定（无法锁定N/2+1个实例或者有效时间为负数），它将尝试解锁所有实例（即使它认为自己无法锁定某些实例）。

### 算法是异步的吗？

该算法依赖于一个假设：虽然进程之间没有同步时钟，但每个进程的本地时间以大约相同的速率更新，与锁的自动释放时间相比有一个较小的误差范围。这个假设很接近于现实世界中的计算机：每台计算机都有一个本地时钟，并且我们通常可以依赖于不同计算机之间的时钟漂移很小。

在这一点上，我们需要更明确我们的互斥规则：只有在客户端持有锁并在锁的有效时间内完成工作（如第3步所得），减去一些时间（仅需几毫秒以补偿进程间的时钟漂移），才能保证互斥。

这篇论文包含更多关于需要一个有界的*时钟漂移*的类似系统的信息: [Leases: an efficient fault-tolerant mechanism for distributed file cache consistency](http://dl.acm.org/citation.cfm?id=74870)。

### 失败时重试

当客户端无法获取锁时，应该在随机延迟后再次尝试，以尝试使多个客户端在同一时间尝试获取相同资源的锁时发生歧义，从而避免分裂脑的情况（这可能导致没有人成功）。此外，在大多数Redis实例中，客户端尝试获取锁的速度越快，发生分裂脑情况的窗口就越小（也就是需要重试的可能性更小），所以理想情况下，客户端应该尝试同时使用多路复用将`SET`命令发送到N个实例。

值得强调的是，对于未能获取大部分锁的客户端来说，尽快释放（部分）获取的锁非常重要，这样就不需要等待键的到期时间再次获取锁（然而，如果发生网络分区且客户端无法与Redis实例进行通信，则需要付出可用性的惩罚，因为它会等待键的到期时间）。

### 释放锁定

释放锁定是简单的，无论客户端是否相信自己能成功锁定某个实例，都可以执行此操作。

### 安全论证

算法是安全的吗？让我们在不同的情况下进行检查。

为了开始，让我们假设客户端在大多数情况下能够获取锁定。所有实例将包含具有相同存活时间的键。然而，这些键是在不同的时间设置的，因此键的过期时间也不同。但是，如果第一个键在最差情况下在时间T1设置（即在与第一个服务器联系之前的时间点采样），并且最后一个键在最差情况下在时间T2设置（即在从最后一个服务器获得回复之前的时间点采样），我们确定集合中最先过期的键将至少存在于`MIN_VALIDITY=TTL-(T2-T1)-CLOCK_DRIFT`的时间内。所有其他键将在此之后过期，因此我们确定这些键将同时设置至少这段时间。

在大多数键已设置的情况下，另一个客户端将无法获取锁，因为如果已存在N/2+1个键，则无法成功执行N/2+1个SET NX操作。因此，如果已获取锁，则不可能同时重新获取锁（违反了互斥属性）。

然而，我们还希望确保多个客户端在同时尝试获取锁时不能同时成功。

如果一个客户端在接近或超过锁的最大有效时间（我们用于 SET 的 TTL）内锁定了大部分实例，那么它将认为该锁无效并解锁这些实例，因此我们只需要考虑客户端在有效时间内成功锁定大多数实例的情况。在这种情况下，根据前面提出的论点，在 `MIN_VALIDITY` 时间内，没有客户端应该能够重新获得锁定。因此，只有当锁定大多数实例所需的时间大于 TTL 时间时，多个客户端才能在相同的时间（即第 2 步的结束时间）锁定 N/2+1 个实例，使得锁定无效。

### 存活性参数

系统活跃度基于三个主要特征：

1. 锁的自动释放（因为键过期）：最终键再次可用以进行锁定。
2. 通常情况下，客户端将配合在锁未被获取或锁获取并且工作终止时移除锁定的情况，这使得我们不必等待键过期以重新获取锁定的可能性增加。
3. 当客户端需要重试锁定时，它会等待一个相对较长时间，此时间比获得大多数锁所需的时间更长，以在资源争用期间通过概率方式减少脑裂状况的发生可能性。

然而，我们在网络分区上支付一个等于`TTL`时间的可用性惩罚，因此如果存在连续的分区，我们可以无限期地支付此惩罚。
每当客户端获取锁并在能够释放锁之前被分区时，就会发生这种情况。

基本上，如果存在无限连续的网络分区，系统可能无法无限时间地提供服务。

### 性能，崩溃恢复和fsync

很多将Redis用作锁服务器的用户需要高性能，既需要在获取和释放锁时具有低延迟，也需要每秒能够执行的获取/释放操作数量高。为了满足此要求，与N个Redis服务器通信以减少延迟的策略绝对是复用（将套接字设为非阻塞模式，发送所有命令，并稍后读取所有命令，假设客户端与每个实例之间的往返时间（RTT）大致相同）。

然而，如果我们想针对崩溃恢复系统模型进行持久化考虑，那么还有另一个要考虑的因素。

基本上，为了看到这里的问题，让我们假设我们完全没有配置 Redis 持久化。一个客户端在 5 个实例中的 3 个实例上获取了锁定。其中一个实例在客户端能够获取锁定之后重新启动，在这一点上，我们可以再次为相同的资源锁定 3 个实例，而另一个客户端可以再次锁定它，从而违反了锁定的排他性安全属性。

如果我们启用AOF持久化，情况会好很多。例如，我们可以通过发送`SHUTDOWN`命令并重启服务器来进行升级。因为Redis的过期操作是语义上实现的，所以即使服务器关闭了，时间仍在流逝，满足我们的所有要求。
然而，只有在干净的关闭情况下一切才会好。那么停电怎么办？如果Redis配置使用默认设置，在每秒钟都会将数据同步到磁盘上，重启后可能会导致我们的键丢失。理论上，如果我们想要在任何实例重启情况下保证锁的安全性，我们需要在持久化设置中启用`fsync=always`。这会影响性能，因为会增加额外的同步开销。

然而，事情并不像一开始看起来的那样糟糕。基本上，只要在崩溃后的重启过程中，实例不再参与任何**当前活跃的**锁定，算法的安全性就得以保留。这意味着，在实例重新加入系统时，当前活跃的锁集合都是通过锁定其他实例而获得的，而不是通过该实例获得的。

为了保证这一点，我们只需要创建一个实例，在崩溃后，至少保持不可用时间超过我们使用的最大“TTL”。这是在实例崩溃时存在的所有关于锁的键失效并自动释放的所需时间。

使用*延迟重启*，基本上可以实现安全性，即使没有任何Redis持久性可用，但请注意这可能会导致可用性损失。例如，如果大多数实例崩溃，系统将在此期间变为全局不可用（全局表示此时任何资源都不可锁定）。

### 提高算法的可靠性：扩展锁定功能

如果客户端执行的工作由小步骤组成，默认情况下可能使用较短的锁有效时间，并扩展实施锁扩展机制的算法。基本上，如果客户端在计算过程中发现锁的有效性接近较低值，可以通过向所有实例发送一个Lua脚本来延长锁的有效期，前提是该键存在且其值仍为客户端在获取锁时分配的随机值。

如果客户端能够将锁延长到大多数实例并且在有效时间内重新获取锁，则应该将其视为重新获取了锁（基本上，使用的算法与获取锁时使用的算法非常相似）。

然而，从技术上讲，这并不改变算法，因此重新获取锁的最大尝试次数应该受到限制，否则将违反其中一个活性属性。

### 关于一致性的免责声明

请仔细考虑最后这一页上《Redlock分析》部分的内容。
Martin Kleppman的文章以及antirez对此的回答非常相关。
如果你关心一致性和正确性，你应该注意以下几个主题：

1. 你应该实现栅栏令牌。对于可能需要较长时间的过程来说，这尤为重要，并适用于任何分布式锁系统。延长锁的生存时间也是一种选择，但不要假设锁会在获取它的进程存活期间一直保持。
2. Redis在TTL过期机制中没有使用单调时钟。这意味着时钟偏移可能导致多个进程获取到同一个锁。尽管通过防止管理员手动设置服务器时间和正确设置NTP等方法可以缓解这个问题，但在实际生活中仍然存在出现这个问题并破坏一致性的机会。

## 想要帮忙吗？

如果你对分布式系统感兴趣，很乐意听取你的意见/分析。其他语言的实现参考也将非常有用。

谢谢！

## Redlock分析

1. Martin Kleppmann [在此分析了 Redlock](http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)。与这种分析相反的观点可以在[这里找到](http://antirez.com/news/101)。
